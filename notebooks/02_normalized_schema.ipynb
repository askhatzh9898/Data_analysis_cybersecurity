{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unified Schema for Network Security Analytics\n",
    "\n",
    "Normalize Zeek `conn.log` and `dns.log` into a single, consistent schema\n",
    "ready for enrichment, detection rules, and cross-source correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from scripts.zeek_to_dataframe import load_zeek_log, CONN_SCHEMA, DNS_SCHEMA\n",
    "from scripts.normalize import (\n",
    "    normalize_conn,\n",
    "    normalize_dns,\n",
    "    merge_normalized,\n",
    "    UNIFIED_SCHEMA,\n",
    ")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 — Load raw Zeek logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZEEK_DIR = Path(\"../data/zeek_logs/sample\")\n",
    "\n",
    "conn_raw = load_zeek_log(ZEEK_DIR / \"conn.log\", schema=CONN_SCHEMA)\n",
    "dns_raw = load_zeek_log(ZEEK_DIR / \"dns.log\", schema=DNS_SCHEMA)\n",
    "\n",
    "print(f\"conn.log: {len(conn_raw)} rows, {len(conn_raw.columns)} columns\")\n",
    "print(f\"dns.log:  {len(dns_raw)} rows, {len(dns_raw.columns)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw Zeek field names — these differ between log types\n",
    "print(\"conn.log columns:\", list(conn_raw.columns))\n",
    "print()\n",
    "print(\"dns.log columns:\", list(dns_raw.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 — Normalize to unified schema\n",
    "\n",
    "Field mapping:\n",
    "\n",
    "| Zeek field | Unified field | Notes |\n",
    "|------------|---------------|-------|\n",
    "| `ts` | `timestamp` | Already datetime64[ns, UTC] |\n",
    "| `id.orig_h` | `src_ip` | Source IP address |\n",
    "| `id.orig_p` | `src_port` | Source port |\n",
    "| `id.resp_h` | `dst_ip` | Destination IP address |\n",
    "| `id.resp_p` | `dst_port` | Destination port |\n",
    "| `proto` | `protocol` | tcp, udp, icmp |\n",
    "| `query` | `dns_query` | DNS-specific |\n",
    "| `qtype_name` | `dns_qtype` | DNS-specific |\n",
    "| `rcode_name` | `dns_rcode` | DNS-specific |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_norm = normalize_conn(conn_raw)\n",
    "dns_norm = normalize_dns(dns_raw)\n",
    "\n",
    "print(f\"Normalized conn: {len(conn_norm)} rows, {len(conn_norm.columns)} columns\")\n",
    "print(f\"Normalized dns:  {len(dns_norm)} rows, {len(dns_norm.columns)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both DataFrames now share the same column names\n",
    "print(\"Unified columns:\", list(conn_norm.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect normalized conn data\n",
    "conn_norm[[\"timestamp\", \"log_type\", \"src_ip\", \"dst_ip\", \"dst_port\", \"protocol\", \"service\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect normalized dns data — note dns_* fields are populated\n",
    "dns_norm[[\"timestamp\", \"log_type\", \"src_ip\", \"dst_ip\", \"protocol\", \"dns_query\", \"dns_rcode\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify consistent dtypes across both normalized DataFrames\n",
    "print(\"conn_norm dtypes:\")\n",
    "print(conn_norm.dtypes.to_string())\n",
    "print()\n",
    "print(\"dns_norm dtypes:\")\n",
    "print(dns_norm.dtypes.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 — Merge into single unified DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unified = merge_normalized(conn_norm, dns_norm)\n",
    "\n",
    "print(f\"Unified DataFrame: {len(unified)} rows\")\n",
    "print(f\"Log type distribution:\")\n",
    "print(unified[\"log_type\"].value_counts().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorted by timestamp — interleaved conn and dns events\n",
    "unified[[\"timestamp\", \"log_type\", \"src_ip\", \"dst_ip\", \"dst_port\", \"protocol\", \"dns_query\"]].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 — Ready for enrichment\n",
    "\n",
    "The unified DataFrame can now be passed to enrichment pipelines that expect\n",
    "consistent field names. Example enrichments:\n",
    "\n",
    "- **GeoIP lookup** on `src_ip` and `dst_ip`\n",
    "- **ASN lookup** to identify hosting providers\n",
    "- **Threat intel matching** against `dst_ip` or `dns_query`\n",
    "- **Internal/external tagging** based on RFC1918 ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: tag internal vs external destination IPs\n",
    "import ipaddress\n",
    "\n",
    "PRIVATE_NETWORKS = [\n",
    "    ipaddress.ip_network(\"10.0.0.0/8\"),\n",
    "    ipaddress.ip_network(\"172.16.0.0/12\"),\n",
    "    ipaddress.ip_network(\"192.168.0.0/16\"),\n",
    "]\n",
    "\n",
    "def is_internal(ip_str: str) -> bool:\n",
    "    \"\"\"Return True if IP is in RFC1918 private ranges.\"\"\"\n",
    "    if pd.isna(ip_str):\n",
    "        return False\n",
    "    try:\n",
    "        ip = ipaddress.ip_address(ip_str)\n",
    "        return any(ip in net for net in PRIVATE_NETWORKS)\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "unified[\"dst_internal\"] = unified[\"dst_ip\"].apply(is_internal)\n",
    "\n",
    "print(\"Destination IP classification:\")\n",
    "print(unified[\"dst_internal\"].value_counts().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External connections only — typical scope for threat hunting\n",
    "external = unified[~unified[\"dst_internal\"]]\n",
    "external[[\"timestamp\", \"log_type\", \"src_ip\", \"dst_ip\", \"dst_port\", \"dns_query\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export unified dataset\n",
    "out_path = Path(\"../data/processed/unified.parquet\")\n",
    "unified.to_parquet(out_path, index=False)\n",
    "print(f\"Wrote {len(unified)} rows to {out_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
