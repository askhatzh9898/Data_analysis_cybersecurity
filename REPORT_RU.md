# Анализ сетевой телеметрии для выявления угроз информационной безопасности


## Аннотация

В работе описан воспроизводимый конвейер обработки сетевой телеметрии, сформированной на основе анализа перехваченного трафика. Исходные PCAP-файлы преобразуются системой Zeek в структурированные журналы, после чего данные проходят этапы нормализации, обогащения индикаторами угроз и статистической обработки. Применение данного подхода позволило выявить два узла с признаками компрометации. Результаты демонстрируют, что многоуровневая обработка и обогащение сетевых событий существенно повышают информативность анализа даже при относительно небольшом объёме исходных данных.

## 1. Введение

Мониторинг сетевого трафика является одним из базовых механизмов обеспечения кибербезопасности корпоративной инфраструктуры. Однако необработанные пакетные данные обладают высокой сложностью и требуют структурирования для последующего анализа. В связи с этим возникает необходимость построения автоматизированных конвейеров обработки, обеспечивающих преобразование, унификацию и аналитическое обогащение телеметрии.

В данной работе реализован воспроизводимый конвейер на базе инструментов с открытым исходным кодом, пригодный для применения в средах с ограниченными вычислительными ресурсами.

**Основные задачи исследования:**
1. Преобразование PCAP-файлов в структурированные журналы, пригодные для аналитической обработки
2. Приведение разнородных логов к унифицированной схеме
3. Интеграция индикаторов угроз в сетевые события
4. Выявление подозрительных поведенческих паттернов на основе интерпретируемых статистических показателей


## 2. Источники данных

### 2.1 Основной источник: журналы Zeek

В качестве инструмента сетевого мониторинга использована система Zeek (ранее Bro). Выбор обусловлен её возможностями детализированного протокольного анализа и формированием структурированных журналов.

| Критерий | Характеристика |
|----------|------------------|
| Поддержка протоколов | Нативный разбор более 35 прикладных протоколов |
| Формат журналов | Структурированные журналы (TSV или JSON) с типизированными полями |
| Работа с PCAP | Поддержка воспроизведения PCAP через `zeek -r` |
| Расширяемость | Возможность написания скриптов для анализа пользовательских протоколов |

В анализе использовались `conn.log` (сводки соединений) и `dns.log` (DNS-транзакции), которые в совокупности обеспечивают видимость топологии сети и паттернов разрешения имён.

### 2.2 Справочные данные: индикаторы угроз

Для этапа обогащения применялись локальные списки компрометации:
- перечень IP-адресов, ассоциированных с C2-инфраструктурой
- список доменов с признаками вредоносной активности

Использование локальных файлов вместо внешних API-сервисов позволило обеспечить воспроизводимость анализа и исключить зависимость от внешних источников.


## 3. Архитектура конвейера обработки

Процесс реализован в виде последовательности логически разделённых этапов:

```
┌─────────────┐    ┌─────────────┐    ┌─────────────┐    ┌─────────────┐    ┌─────────────┐
│  PCAP       │───▶│НОРМАЛИЗАЦИЯ │───▶│ Обогащение  │───▶│  АНАЛИТИКА  │───▶│   ЭКСПОРТ   │
│  Парсинг    │    │             │    │             │    │             │    │             │
│ Zeek JSON   │    │             │    │             │    │             │    │             │
└─────────────┘    └─────────────┘    └─────────────┘    └─────────────┘    └─────────────┘
```

### 3.1 Загрузка и предварительная обработка

JSON-журналы Zeek импортируются в pandas DataFrame с учётом схемы типов. На данном этапе выполняются:
- корректная обработка строкового JSON-формата
- преобразование временных меток в формат `datetime64[ns, UTC]`
- использование nullable-типов для числовых полей

### 3.2 Нормализация данных

Поля журналов приводятся к унифицированной схеме, совместимой с принципами Elastic Common Schema (ECS).

| Поле Zeek | Унифицированное поле | 
|-----------|---------------------|
| `id.orig_h` | `src_ip` | 
| `id.resp_h` | `dst_ip` |
| `proto` | `protocol` |
| `ts` | `timestamp` | 

Столбец-дискриминатор `log_type` позволяет фильтровать данные после объединения разнородных журналов.

### 3.3 Обогащение индикаторами угроз

Каждому событию присваивается флаг ti_match, отражающий совпадение с индикаторами компрометации.

Поддерживаются следующие механизмы сопоставления:

- точное совпадение IP-адресов (поиск в множестве)
- сопоставление доменов с учётом поддоменов

Данный этап позволяет интегрировать внешние знания о вредоносной инфраструктуре непосредственно в поток сетевых событий.


### 3.4 Аналитический этап

Вместо применения моделей машинного обучения используются интерпретируемые метрики:

| Метрика | Назначение | 
|---------|--------|
| Доля неудачных соединений | Выявление сканирования и блокировок | 
| Процент NXDOMAIN | Детекция возможных DGA-алгоритмов | 
| Соотношение исходящих/входящих байтов | Признаки эксфильтрации |

### 3.5 Экспорт результатов

Итоговые данные сохраняются в формате CSV/JSON. Для обеспечения воспроизводимости вычисляется контрольная сумма SHA-256.


## 4. Результаты анализа

Обработанный тестовый набор включал 12 сетевых соединений и 9 DNS-запросов.

### 4.1 Протокольная структура

| Протокол | Количество | Доля |
|----------|------------|---------|
| TCP | 9 | 75,0% |
| UDP | 3 | 25,0% |

TCP-трафик преимущественно состоял из HTTPS (порт 443) и SSH (порт 22), что соответствует типичным паттернам исходящего трафика предприятия.

### 4.2 Аномальные показатели

| Показатель | Значение | Интерпретация |
|-----------|----------|-------|
| Неудачные соединения | 33,3% | Потенциальное сканирование |
| NXDOMAIN | 33,3% | Возможная DGA-активность |
| Совпадения TI | 6 | Контакты с подозрительной инфраструктурой |

### 4.3 Подозрительные узлы

| Узел | Особенности |
|--------------------|--------------|
| 192.168.1.200 | 3 TI-совпадения, 3 NXDOMAIN | 
| 192.168.1.110 | 3 неудачных TCP-попытки |

Узел 192.168.1.200 демонстрировал характерную DGA-поведенческую модель: множественные обращения к случайно сгенерированным доменам с ответом NXDOMAIN.

Узел 192.168.1.110 осуществлял попытки соединения с последовательными IP-адресами в пределах одной подсети, завершившиеся состоянием S0, что может указывать на сетевую разведку.


## 5. Ограничения исследования

1. Небольшой объём выборки

2. Отсутствие GeoIP-атрибуции

3. Отсутствие анализа временной периодичности

4. Использование статических списков TI

5. Ограниченная видимость сети 


## 6. Перспективы развития

- масштабирование обработки с использованием распределённых фреймворков

- анализ периодичности (beaconing detection)

- использование TLS-отпечатков (JA3/JA3S)

- интеграция с MITRE ATT&CK


## 7. Заключение

Построенный конвейер демонстрирует, что даже при использовании простых статистических методов возможно выявление значимых индикаторов компрометации. Ключевым фактором эффективности является не сложность алгоритмов, а корректная структуризация, нормализация и обогащение сетевых данных. Интерпретируемый подход облегчает проверку результатов аналитиком и соответствует требованиям практической информационной безопасности.


## Список литературы

1. Paxson, V. (1999). Bro: A System for Detecting Network Intruders in Real-Time. *Computer Networks*, 31(23-24), 2435-2463.

2. Elastic. (2023). Elastic Common Schema (ECS) Reference. https://www.elastic.co/guide/en/ecs/current/

3. MaxMind. (2023). GeoLite2 Free Geolocation Data. https://dev.maxmind.com/geoip/geolite2-free-geolocation-data

4. MITRE. (2023). ATT&CK for Enterprise. https://attack.mitre.org/

